{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST with Keras and Deep Learning\n",
    "\n",
    "In this tutorial you will learn how to train a simple Convolutional Neural Network (CNN) with Keras on the Fashion MNIST dataset, enabling you to classify fashion images and categories.\n",
    "\n",
    "The Fashion MNIST dataset is meant to be a (slightly more challenging) drop-in replacement for the (less challenging) MNIST dataset.\n",
    "\n",
    "Similar to the MNIST digit dataset, the Fashion MNIST dataset includes:\n",
    "\n",
    "60,000 training examples\n",
    "10,000 testing examples\n",
    "10 classes\n",
    "28×28 grayscale/single channel images\n",
    "The ten fashion class labels include:\n",
    "\n",
    "T-shirt/top\n",
    "Trouser/pants\n",
    "Pullover shirt\n",
    "Dress\n",
    "Coat\n",
    "Sandal\n",
    "Shirt\n",
    "Sneaker\n",
    "Bag\n",
    "Ankle boot\n",
    "Throughout this tutorial, you will learn how to train a simple Convolutional Neural Network (CNN) with Keras on the Fashion MNIST dataset, giving you not only hands-on experience working with the Keras library but also your first taste of clothing/fashion classification.\n",
    "\n",
    "To learn how to train a Keras CNN on the Fashion MNIST dataset, just keep reading!\n",
    "\n",
    "\n",
    "Looking for the source code to this post?\n",
    "JUMP RIGHT TO THE DOWNLOADS SECTION \n",
    "Fashion MNIST with Keras and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pip install scikit-learn\n",
    "$ pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ tree --dirsfirst\n",
    ".\n",
    "├── pyimagesearch\n",
    "│   ├── __init__.py\n",
    "│   └── minivggnet.py # VGGNet 기반\n",
    "├── fashion_mnist.py\n",
    "└── plot.png\n",
    "1 directory, 4 files\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a simple Convolutional Neural Network (CNN)\n",
    "\n",
    "### MiniVGGNet\n",
    "\n",
    "- The model has VGGNet characteristics, including:\n",
    "    - Only using 3×3 CONV filters\n",
    "    - Stacking multiple CONV layers before applying a max-pooling operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minivggnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()  # 모델 초기화 \n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1 # 마지막 차원 \n",
    "        \n",
    "        # channels_first을 사용하는 경우 inputShape을 갱신 \n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "            \n",
    "            # 모델 투입 \n",
    "            model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(BatchNormalization(axis=chanDim))\n",
    "            model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(BatchNormalization(axis=chanDim))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(0.25))\n",
    "            # second CONV => RELU => CONV => RELU => POOL layer set\n",
    "            model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(BatchNormalization(axis=chanDim))\n",
    "            model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(BatchNormalization(axis=chanDim))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(0.25))\n",
    "            # first (and only) set of FC => RELU layers\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(512))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.5))\n",
    "            # softmax classifier\n",
    "            model.add(Dense(classes))\n",
    "            model.add(Activation(\"softmax\"))\n",
    "            # return the constructed network architecture\n",
    "            return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " CNN 모델은 비교적 단순하다. \n",
    " 그래서 두가지 방법을 권장하는데 \n",
    " 1. 배치 정규화 \n",
    " 2. 드롭 아웃을 활용한다.\n",
    " \n",
    " MiniVGGNet 클래스의 build는 네가지 변수를 허용한다.\n",
    " \n",
    " width   -  이미지 너비(픽셀) \n",
    " height  -  이미지 높이(픽셀)\n",
    " depth   -  채널수, 일반적으로 색상(컬러)의 경우 값은 3 그레이스케일(흑백)의 경우 1 \n",
    " classes -  우리가 인식 할 수있는 패션 기사의 유형의 수 -> 완전히 연결된 최종 레이어에 영향 \n",
    "            데이터 세트는 총 10개의 클래스가 존재 \n",
    "            \n",
    "`model = Sequential()` : Sequential호출해서 초기화 \n",
    "`inputShape` 정의 \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from pyimagesearch.minivggnet import MiniVGGNet\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 25\n",
    "INIT_LR = 1e-2\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the Fashion MNIST dataset (if this is your first time running\n",
    "# this the dataset will be automatically downloaded)\n",
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "# if we are using \"channels first\" ordering, then reshape the design\n",
    "# matrix such that the matrix is:\n",
    "# num_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "    testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    "\n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "# one-hot encode the training and testing labels\n",
    "trainY = np_utils.to_categorical(trainY, 10)\n",
    "testY = np_utils.to_categorical(testY, 10)\n",
    "\n",
    "# initialize the label names\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "    \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
    "\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training model...\")\n",
    "\n",
    "H = model.fit(trainX, trainY,\n",
    "    validation_data=(testX, testY),\n",
    "    batch_size=BS, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set\n",
    "preds = model.predict(testX)\n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
    "    target_names=labelNames))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our list of output images -> 105\n",
    "images = []\n",
    "# randomly select a few testing fashion items\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
    "    # classify the clothing\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    " \n",
    "    # extract the image from the testData if using \"channels_first\"\n",
    "    # ordering\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        image = (testX[i][0] * 255).astype(\"uint8\")\n",
    " \n",
    "    # otherwise we are using \"channels_last\" ordering\n",
    "    else:\n",
    "        image = (testX[i] * 255).astype(\"uint8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
